pretrained_model_name_or_path: 'lambdalabs/sd-image-variations-diffusers'
pretrained_unet_path: 'path_of_your_stage2_model'
revision: null
train_dataset:
  root_dir_ortho: '/mvfs/multiview-data/ortho-13views'  # change to your path
  root_dir_persp: '/mvfs/workspace/data/multiview-renders/persp_13views/persp_13views' # change to your path
  pred_ortho: true
  pred_persp: true
  object_list: './datalist/datalist_single_obj.json'
  invalid_list: null
  num_views: 6
  groups_num: 1
  bg_color: 'three_choices'
  img_wh: [256, 256]
  validation: false
  num_validation_samples: 32
  read_normal: false
  read_color: true
  pred_type: 'joint_color_normal'
  load_cam_type: true
  load_switcher: true
validation_dataset:
  root_dir_ortho: '/mvfs/multiview-data/ortho-13views'  # change to your path
  root_dir_persp: '/mvfs/workspace/data/multiview-renders/persp_13views/persp_13views' # change to your path
  pred_ortho: true
  pred_persp: true
  object_list: './datalist/datalist_single_obj.json'
  invalid_list: null
  num_views: 6
  groups_num: 1
  bg_color: 'three_choices'
  img_wh: [256, 256]
  validation: true
  num_validation_samples: 32
  read_normal: false
  read_color: true
  pred_type: 'joint_color_normal'
  load_cam_type: true
  load_switcher: true
validation_train_dataset:
  root_dir_ortho: '/mvfs/multiview-data/ortho-13views'  # change to your path
  root_dir_persp: '/mvfs/workspace/data/multiview-renders/persp_13views/persp_13views' # change to your path
  pred_ortho: true
  pred_persp: true
  object_list: './datalist/datalist_single_obj.json'
  invalid_list: null
  num_views: 6
  groups_num: 1
  bg_color: 'three_choices'
  img_wh: [256, 256]
  validation: false
  num_validation_samples: 32
  num_samples: 32
  read_normal: false
  read_color: true
  pred_type: 'joint_color_normal'
  load_cam_type: true
  load_switcher: true

pred_type: 'joint_color_normal'

output_dir: 'outputs/stage3-train'
seed: 42
train_batch_size: 24
validation_batch_size: 16
validation_train_batch_size: 16
max_train_steps: 80000
gradient_accumulation_steps: 2
gradient_checkpointing: True
learning_rate: 2.e-5
scale_lr: false
lr_scheduler: "constant_with_warmup"
lr_warmup_steps: 100
snr_gamma: 5.0
use_8bit_adam: false
allow_tf32: true
use_ema: true
dataloader_num_workers: 16
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 1.e-2
adam_epsilon: 1.e-08
max_grad_norm: 1.0
prediction_type: null
vis_dir: vis
logging_dir: logs
mixed_precision: "fp16"
report_to: 'tensorboard'
local_rank: -1
checkpointing_steps: 2500
checkpoints_total_limit: 20
resume_from_checkpoint: latest
enable_xformers_memory_efficient_attention: false
validation_steps: 1250
validation_sanity_check: true
tracker_project_name: 'mvdiffusion-image-v1'

trainable_modules: ['joint_mid']
use_classifier_free_guidance: true
condition_drop_rate: 0.05
drop_type: 'drop_as_a_whole'  # modify
camera_embedding_lr_mult: 10.
scale_input_latents: true

pipe_kwargs:
  camera_embedding_type: 'e_de_da_sincos'
  num_views: 6

validation_guidance_scales: [1., 3.]
pipe_validation_kwargs:
  eta: 1.0
validation_grid_nrow: 12

unet_from_pretrained_kwargs:
  camera_embedding_type: 'e_de_da_sincos'
  projection_class_embeddings_input_dim: 14  # modify
  num_views: 6
  sample_size: 32
  zero_init_conv_in: false
  zero_init_camera_projection: false
  cd_attention_last: false
  cd_attention_mid: true
  multiview_attention: true
  sparse_mv_attention: false
  mvcd_attention: false
  ignore_mismatched_sizes: true

num_views: 6
camera_embedding_type: 'e_de_da_sincos'
